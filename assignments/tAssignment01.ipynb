{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.1"},"colab":{"name":"tAssignment01.ipynb","provenance":[{"file_id":"https://github.com/mlcoursemm/py2020autumn/blob/master/assignments/Assignment01.ipynb","timestamp":1615326245130}],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"fzhtu5vS46aT"},"source":["## Домашнее задание №1"]},{"cell_type":"markdown","metadata":{"id":"0G0UNscp46ad"},"source":["### 1.1 Реализуйте алгоритм машинного обучения из списка"]},{"cell_type":"markdown","metadata":{"id":"SPOZfjqq46af"},"source":["* Алгоритмы **классификации**:\n","  1. Метод k ближайших соседей (алгоритм поиска - полный перебор)\n","  2. Метод k ближайших соседей (алгоритм поиска - balltree)\n","  3. Метод k ближайших соседей (алгоритм поиска - kdtree)\n","\n","\n","* Алгоритмы **регрессии**:\n","  1. Гребневая регрессия (метод обучения - по формуле)\n","  2. Гребневая регрессия (метод обучения - стохастический градиентный спуск, данные подаются по одному примеру с помощью реализованного Вами итератора, градиент вычисляется по формуле)\n","  3. ElasticNet (метод обучения - стохастический градиентный спуск, данные подаются пакетами любого размера с помощью реализованного Вами итератора, градиент вычисляется с помощью численной аппроксимации)\n","  \n","\n","* С применяемыми алгоритмами детальнее можно познакомиться в Лекциях 2 и 4 [курса по машинному обучению](https://github.com/mlcoursemm/ml2020autumn/tree/master/lectures)   \n","\n","\n","* Все вычисления должны быть максимально векторизованы с помощью Numpy"]},{"cell_type":"markdown","metadata":{"id":"7kuC-4Li46ag"},"source":["#### 1.2 Покройте ваш код тестами (3 балла)\n","Тестирование обязательно должно включать в себя: \n","<ul>\n","<li>проверку работоспособности кода</li>\n","<li>корректность работы алгоритма машинного обучения</li>\n","<li>сравнение методов с аналогичными из scikit-learn</li>\n","</ul>"]},{"cell_type":"markdown","metadata":{"id":"v-bBQiY946ah"},"source":["#### 1.3 Примените полученный код к прикладной задаче машинного обучения и настройте гиперпараметры (2 балла)"]},{"cell_type":"markdown","metadata":{"id":"GT_RcljO46ai"},"source":["#### Требования к коду:\n","1. Код должен проходить тесты\n","2. Код должен соотвествовать стандарту pep-8\n","3. Код должен быть хорошо структурирован\n","4. Код должен быть эффективен\n","5. Код должен быть устойчив к иключительным ситуациям\n","6. Необходимо реализовать прделоженные интерфейсы.\n","7. В качестве решения должны быть присланы следующие файлы:\n","  * prefix_model.py - содержит класс, реализующий ваш алгоритм \n","  * prefix_tests.py - содержит класс с тестами\n","  * prefix_run.ipynb - содержит 1) тестирование; 2) реализация пункта 1.3 \n","8. \"prefix\" = \"task01_ФамилияИО\". Например, для Иванова Ивана Ивановича название первого файла будет task01_ivanovii_model.py."]},{"cell_type":"markdown","metadata":{"id":"xepO6uXg46aj"},"source":["## Важно:\n","#### Дедлайн: до 25 апреля 23:59:59\n","#### Решение отправлять на почту курса mlcoursemm@gmail.com\n","#### При отправке указать тему [tpy2021:task01]"]},{"cell_type":"markdown","metadata":{"id":"fXzINBa246aj"},"source":["#### Примеры интерфейсов "]},{"cell_type":"code","metadata":{"id":"OGmCTNzK46ak"},"source":["class RidgeAnalyticalRegressor(object):\n","    '''Класс для предсказания действительно-значного выхода по входу - вектору из R^n. \n","    Используется линейная регрессия, то есть если вход X \\in R^n, вектор весов W \\in R^n,\n","    то значение регрессии - это X^T * W, то есть y = x1*w1 + x2*w2 + xn*wn.\n","    Считается, что единичный признак уже входит в X.\n","    Обучение - подгонка весов W - будет вестись на парах (x, y).\n","    \n","    Параметры\n","    ----------\n","    l2_coef    : коэффициент l2 регуляризации  \n","    \n","    !!! Внимание: вектор весов W должен быть обязательно объявлен как поле класса Regression.coef_ !!!\n","    '''\n","    # Конструктор для п. 1 (конкретное значение параметра выбирается либо настраивается студентом)\n","    def __init__(self, l2_coef=100.0):\n","        pass\n","    \n","    def fit(self, X, y):\n","        '''Обучение модели.\n","        \n","        Параметры\n","        ----------\n","        X : двумерный массив признаков размера n_samples x n_features \n","        y : массив/список правильных значений размера n_samples\n","        \n","        Выход\n","        -------\n","        Метод обучает веса W\n","        '''\n","        pass\n","        \n","    def predict(self, X):\n","        \"\"\" Предсказание выходного значения для входных векторов\n","        \n","        Параметры\n","        ----------\n","        X : двумерный массив признаков размера n_samples x n_features\n","        \n","        Выход\n","        -------\n","        y : Массив размера n_samples\n","        \"\"\"\n","        pass\n","        \n","    def score(self, y_gt, y_pred):\n","        \"\"\"Возвращает точность регрессии в виде (1 - u/v) - т.е. R^2-score, \n","        где u - суммарный квадрат расхождения y_gt с y_pred,\n","        v - суммарный квадрат расхождения y_gt с матожиданием y_gt\n","        \n","        Параметры\n","        ----------\n","        y_gt : массив/список правильных значений размера n_samples\n","        y_pred : массив/список предсказанных значений размера n_samples\n","        \n","        Выход\n","        -------\n","        accuracy - точность регрессии\n","        \"\"\"\n","        pass\n","    \n","class RidgeRegressor(object):\n","     '''Класс для предсказания действительно-значного выхода по входу - вектору из R^n. \n","    Используется линейная регрессия, то есть если вход X \\in R^n, вектор весов W \\in R^n,\n","    то значение регрессии - это X^T * W, то есть y = x1*w1 + x2*w2 + xn*wn.\n","    Считается, что единичный признак уже входит в X.\n","    Обучение - подгонка весов W - будет вестись на парах (x, y).\n","    \n","    Параметры\n","    ----------\n","    n_epoch    : количество эпох обучения \n","    alpha      : градиентный шаг\n","    l2_coef    : коэффициент l2 регуляризации  \n","    \n","    !!! Внимание: вектор весов W должен быть обязательно объявлен как поле класса Regression.coef_ !!!\n","    '''\n","    # Конструктор для п. 2 (конкретное значение параметра выбирается либо настраивается студентом)\n","    def __init__(self, n_epoch=100, alpha=100., l2_coef=100.0):\n","        pass   \n","    \n","    def fit(self, X, y):\n","        pass\n","        \n","    def predict(self, X):\n","        pass\n","        \n","    def score(self, y_gt, y_pred):\n","        pass\n","          \n","class ElasticNetRegressor(object):\n","    '''Класс для предсказания действительно-значного выхода по входу - вектору из R^n. \n","    Используется линейная регрессия, то есть если вход X \\in R^n, вектор весов W \\in R^n,\n","    то значение регрессии - это X^T * W, то есть y = x1*w1 + x2*w2 + xn*wn.\n","    Считается, что единичный признак уже входит в X.\n","    Обучение - подгонка весов W - будет вестись на парах (x, y).\n","    \n","    Параметры\n","    ----------\n","    n_epoch    : количество эпох обучения \n","    alpha      : градиентный шаг \n","    batch_size : размер пакета для шага SGD \n","    delta      : параметр численного дифференцирования      \n","    l1_coef    : коэффициент l1 регуляризации\n","    l2_coef    : коэффициент l2 регуляризации  \n","    \n","    !!! Внимание: вектор весов W должен быть обязательно объявлен как поле класса Regression.coef_ !!!\n","    '''\n","    # Конструктор для п. 3 (конкретное значение параметра выбирается либо настраивается студентом)\n","    def __init__(self, n_epoch=100, batch_size=100, alpha=100., delta=100.0, \n","                 l1_coef=100.0, l2_coef=100.0):\n","        pass \n","    \n","    def fit(self, X, y):\n","        pass\n","        \n","    def predict(self, X):\n","        pass\n","        \n","    def score(self, y_gt, y_pred):\n","        pass "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SvApGsUG46an"},"source":["class KnnBruteClassifier(object):\n","    '''Классификатор реализует взвешенное голосование по ближайшим соседям. \n","    Поиск ближайшего соседа осуществляется полным перебором.\n","    Параметры\n","    ----------\n","    n_neighbors : int, optional\n","        Число ближайших соседей, учитывающихся в голосовании\n","    weights : str, optional (default = 'uniform')\n","        веса, используемые в голосовании. Возможные значения:\n","        - 'uniform' : все веса равны.\n","        - 'distance' : веса обратно пропорциональны расстоянию до классифицируемого объекта\n","        -  функция, которая получает на вход массив расстояний и возвращает массив весов\n","    metric: функция подсчета расстояния (по умолчанию l2).\n","    '''\n","    def __init__(self, n_neighbors=1, weights='uniform', metric):\n","        pass\n","     \n","    def fit(self, x, y):\n","        '''Обучение модели.\n","        Парметры\n","        ----------\n","        x : двумерным массив признаков размера n_queries x n_features\n","        y : массив/список правильных меток размера n_queries\n","        Выход\n","        -------\n","        Метод возвращает обученную модель\n","        '''\n","        pass\n","        \n","    def predict(self, x):\n","        \"\"\" Предсказание класса для входных объектов\n","        Параметры\n","        ----------\n","        X : двумерным массив признаков размера n_queries x n_features\n","        Выход\n","        -------\n","        y : Массив размера n_queries\n","        \"\"\"\n","        pass\n","        \n","    def predict_proba(self, X):\n","        \"\"\"Возвращает вероятности классов для входных объектов\n","        Параметры\n","        ----------\n","        X : двумерным массив признаков размера n_queries x n_features\n","        Выход\n","        -------\n","        p : массив размера n_queries x n_classes] c вероятностями принадлежности \n","        объекта к каждому классу\n","        \"\"\"\n","        pass\n","        \n","    def kneighbors(self, x, n_neighbors):\n","        \"\"\"Возвращает n_neighbors ближайших соседей для всех входных объектов и расстояния до них\n","        Параметры\n","        ----------\n","        X : двумерным массив признаков размера n_queries x n_features\n","        Выход\n","        -------\n","        neigh_dist массив размера n_queries х n_neighbors\n","        расстояния до ближайших элементов\n","        neigh_indarray, массив размера n_queries x n_neighbors\n","        индексы ближайших элементов\n","        \"\"\"\n","        pass\n","\n","class KnnBalltreeClassifier(object):\n","    '''Классификатор реализует взвешенное голосование по ближайшим соседям. \n","    При подсчете расcтояния используется l2-метрика.\n","    Поиск ближайшего соседа осуществляется поиском по ball-дереву.\n","    Параметры\n","    ----------\n","    n_neighbors : int, optional\n","        Число ближайших соседей, учитывающихся в голосовании\n","    weights : str, optional (default = 'uniform')\n","        веса, используемые в голосовании. Возможные значения:\n","        - 'uniform' : все веса равны.\n","        - 'distance' : веса обратно пропорциональны расстоянию до классифицируемого объекта\n","        -  функция, которая получает на вход массив расстояний и возвращает массив весов\n","    leaf_size: int, optional\n","        Максимально допустимый размер листа дерева\n","    '''\n","    def __init__(self, n_neighbors=1, weights='uniform', leaf_size=30):\n","        pass\n","     \n","    def fit(self, x, y):\n","        pass\n","        \n","    def predict(self, x):\n","        pass\n","        \n","    def predict_proba(self, X):\n","        pass\n","        \n","    def kneighbors(self, x, n_neighbors):\n","        pass\n","\n","class KnnKdtreeClassifier(object):\n","    '''Классификатор реализует взвешенное голосование по ближайшим соседям. \n","    При подсчете расcтояния используется l1-метрика.\n","    Поиск ближайшего соседа осуществляется поиском по kd-дереву.\n","    Параметры\n","    ----------\n","    n_neighbors : int, optional\n","        Число ближайших соседей, учитывающихся в голосовании\n","    weights : str, optional (default = 'uniform')\n","        веса, используемые в голосовании. Возможные значения:\n","        - 'uniform' : все веса равны.\n","        - 'distance' : веса обратно пропорциональны расстоянию до классифицируемого объекта\n","        -  функция, которая получает на вход массив расстояний и возвращает массив весов\n","    leaf_size: int, optional\n","        Максимально допустимый размер листа дерева\n","    '''\n","    def __init__(self, n_neighbors=1, weights='uniform', leaf_size=30):\n","        pass\n","     \n","    def fit(self, x, y):\n","        pass\n","        \n","    def predict(self, x):\n","        pass\n","        \n","    def predict_proba(self, X):\n","        pass\n","        \n","    def kneighbors(self, x, n_neighbors):\n","        pass"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0jZiOnPg46aq"},"source":["#### Пример файла: task01_ivanovii_run.ipynb"]},{"cell_type":"markdown","metadata":{"id":"Ftpzag-Z46at"},"source":["* Для задачи регрессии"]},{"cell_type":"code","metadata":{"id":"h9RlDqsh46at"},"source":["from task01_ivanovii_tests import test_regression_model\n","from task01_ivanovii_model import ElasticNetRegressor\n","\n","model = ElasticNetRegressor(...) #инициализация Вашей модели с нужными параметрами\n","test_regression_model(model)\n","\n","#далее идут другие тесты (чем больше - тем лучше)\n","# код пункта 1.3"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7oT6B2iW46au"},"source":["* Для задачи классификации"]},{"cell_type":"code","metadata":{"id":"YGhrpbuE46au"},"source":["from task01_ivanovii_tests import test_knn_model\n","from task01_ivanovii_model import KnnKdtreeClassifier\n","\n","model = KnnKdtreeClassifier(...) #инициализация Вашей модели с нужными параметрами\n","test_knn_model(model)\n","\n","#далее идут другие тесты (чем больше - тем лучше)\n","# код пункта 1.3"],"execution_count":null,"outputs":[]}]}
